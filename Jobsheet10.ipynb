{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWyC2cBzW5y2q4RHHmf/M8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhafillahAkbar/MachLearn_Ganjil_2023/blob/main/Jobsheet10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Work 1"
      ],
      "metadata": {
        "id": "_JdmvTG9GPZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "n_01VXe1GSJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "metadata": {
        "id": "UXu_720XGTpt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ],
      "metadata": {
        "id": "ueUevJkMGPI-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Input pipeline"
      ],
      "metadata": {
        "id": "mgqtjiG0Gi0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CuVUeouJFsZB",
        "outputId": "4e672df4-535f-4796-81ad-1caa08809043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ],
      "metadata": {
        "id": "7v8HJD2OHAP0",
        "outputId": "142bc825-4a35-40b4-c8e5-4770fe176a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ],
      "metadata": {
        "id": "0uI2DbOBHD-C",
        "outputId": "a223b4bb-595b-4c8c-c6d5-4bc8f33b013b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b\"Despite a tight narrative, Johnnie To's Election feels at times like it was once a longer picture, with many characters and plot strands abandoned or ultimately unresolved. Some of these are dealt with in the truly excellent and far superior sequel, Election 2: Harmony is a Virtue, but it's still a dependably enthralling thriller about a contested Triad election that bypasses the usual shootouts and explosions (though not the violence) in favour of constantly shifting alliances that can turn in the time it takes to make a phone call. It's also a film where the most ruthless character isn't always the most threatening one, as the chilling ending makes only too clear: one can imagine a lifetime of psychological counselling being necessary for all the trauma that one inflicts on one unfortunate bystander.<br /><br />Simon Yam, all too often a variable actor but always at his best under To's direction, has possibly never been better in the lead, not least because Tony Leung's much more extrovert performance makes his stillness more the powerful.\"\n",
            " b\"****Excellent<br /><br />***Good<br /><br />**Fair<br /><br />*Poor<br /><br />`Go Ahead, make my Day!' <br /><br />The fourth picture in the series is directed by Eastwood himself (Who was rumored of directing most of Magnum Force) and he brings back the violent society from the first two films. However, the film still lacks impact and believability. This film was released in the early `80s, the time of Regan and the young republicans. The premise of a raped woman taking vengeance on her rapist doesn't appeal to this time frame. This plot would have been better for the Enforcer, which actually would have made it a good movie. What Sudden Impact needed was a plot like in Wall Street but with Dirty Harry in the middle. <br /><br />RATING: 3 STARS\"\n",
            " b\"In his first go as a Hollywood director, Henry Brommell whips an enthralling yarn that is all of penetrating relatable marital issues with melancholic authenticity, and lacing such with an equally absorbing subplot of a father-son hit-man business. The film is directed astutely and consists of a wonderfully put together cast as well as a swift, family-conscious screenplay (also by Brommell) that brings life to an otherwise fatigued genre. As a bonus, 'Panic' delivers subtle, acerbic humor\\xc2\\x97an unexpected, undeniably charming, and very welcome surprise\\xc2\\x97through its bumbling, unsure-of-himself, low-key star, whose ever-cool state is enticing, especially given his line of work.<br /><br />The forever-great William H. Macy again captures our hearts as Alex, a unhappy, torn, middle-aged husband and father who finds solace in the most dubious of persons: a young, attractive, equally-messed-up 23-year-old named Sarah (Neve Campbell), whom he meets in the waiting-room at a psychologist's office, where he awaits the therapy of Dr. Josh Parks (John Ritter) to discuss his growing eagerness to quit the family business that his father (Donald Sutherland) built. Alex, whose lust to lead a new life is obstructed by the fear of disappointing his dictating father, strikes an unwise fancy for Sarah, which ultimately leads him to understand the essence and irrefutable responsibility of being a husband to his wife and, more importantly to him, a good father to his six-year-old son, Sammy (played enthusiastically by the endearing David Dorfman).<br /><br />Henry Brommell's brilliant 'Panic' is something of a rarity in Hollywood seldom seen (with the exception of 2002's 'Road to Perdition') since its conception in 2000\\xc2\\x97it weaves two conflicting genres (organized-crime, family drama) into a fascinating, warm hunk of movie-viewing that is evenly strong in either direction\\xc2\\x97and it's one that will maintain its exceptional, infrequent caliber and gleaming sincerity for ages to come.\"]\n",
            "\n",
            "labels:  [1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a text Encoder"
      ],
      "metadata": {
        "id": "CPicnQ5zHLzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "metadata": {
        "id": "7M_DswMCHKqZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "metadata": {
        "id": "m9IP7A38HP_L",
        "outputId": "7bdb48c3-2ae0-4121-f4d8-195ee15e3834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example=encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "id": "rd0A_pejHUpC",
        "outputId": "ba9a737f-7983-492a-ce81-a35a85c65f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[450,   4,   1, ...,   0,   0,   0],\n",
              "       [  1,  13,   1, ...,   0,   0,   0],\n",
              "       [  8,  25,  86, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ],
      "metadata": {
        "id": "AYmxg9dzHZln",
        "outputId": "edb6a118-0bb4-44f5-d8f9-b3c0ce731932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b\"Despite a tight narrative, Johnnie To's Election feels at times like it was once a longer picture, with many characters and plot strands abandoned or ultimately unresolved. Some of these are dealt with in the truly excellent and far superior sequel, Election 2: Harmony is a Virtue, but it's still a dependably enthralling thriller about a contested Triad election that bypasses the usual shootouts and explosions (though not the violence) in favour of constantly shifting alliances that can turn in the time it takes to make a phone call. It's also a film where the most ruthless character isn't always the most threatening one, as the chilling ending makes only too clear: one can imagine a lifetime of psychological counselling being necessary for all the trauma that one inflicts on one unfortunate bystander.<br /><br />Simon Yam, all too often a variable actor but always at his best under To's direction, has possibly never been better in the lead, not least because Tony Leung's much more extrovert performance makes his stillness more the powerful.\"\n",
            "Round-trip:  despite a [UNK] [UNK] [UNK] [UNK] [UNK] feels at times like it was once a [UNK] picture with many characters and plot [UNK] [UNK] or [UNK] [UNK] some of these are [UNK] with in the truly excellent and far [UNK] sequel [UNK] 2 [UNK] is a [UNK] but its still a [UNK] [UNK] thriller about a [UNK] [UNK] [UNK] that [UNK] the usual [UNK] and [UNK] though not the violence in [UNK] of [UNK] [UNK] [UNK] that can turn in the time it takes to make a [UNK] call its also a film where the most [UNK] character isnt always the most [UNK] one as the [UNK] ending makes only too clear one can imagine a [UNK] of [UNK] [UNK] being [UNK] for all the [UNK] that one [UNK] on one [UNK] [UNK] br [UNK] [UNK] all too often a [UNK] actor but always at his best under [UNK] direction has possibly never been better in the lead not least because [UNK] [UNK] much more [UNK] performance makes his [UNK] more the powerful                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
            "\n",
            "Original:  b\"****Excellent<br /><br />***Good<br /><br />**Fair<br /><br />*Poor<br /><br />`Go Ahead, make my Day!' <br /><br />The fourth picture in the series is directed by Eastwood himself (Who was rumored of directing most of Magnum Force) and he brings back the violent society from the first two films. However, the film still lacks impact and believability. This film was released in the early `80s, the time of Regan and the young republicans. The premise of a raped woman taking vengeance on her rapist doesn't appeal to this time frame. This plot would have been better for the Enforcer, which actually would have made it a good movie. What Sudden Impact needed was a plot like in Wall Street but with Dirty Harry in the middle. <br /><br />RATING: 3 STARS\"\n",
            "Round-trip:  [UNK] br [UNK] br [UNK] br [UNK] br go [UNK] make my day br br the [UNK] picture in the series is directed by [UNK] himself who was [UNK] of directing most of [UNK] [UNK] and he brings back the [UNK] society from the first two films however the film still [UNK] [UNK] and [UNK] this film was released in the early 80s the time of [UNK] and the young [UNK] the premise of a [UNK] woman taking [UNK] on her [UNK] doesnt [UNK] to this time [UNK] this plot would have been better for the [UNK] which actually would have made it a good movie what [UNK] [UNK] needed was a plot like in [UNK] street but with [UNK] [UNK] in the middle br br rating 3 stars                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
            "\n",
            "Original:  b\"In his first go as a Hollywood director, Henry Brommell whips an enthralling yarn that is all of penetrating relatable marital issues with melancholic authenticity, and lacing such with an equally absorbing subplot of a father-son hit-man business. The film is directed astutely and consists of a wonderfully put together cast as well as a swift, family-conscious screenplay (also by Brommell) that brings life to an otherwise fatigued genre. As a bonus, 'Panic' delivers subtle, acerbic humor\\xc2\\x97an unexpected, undeniably charming, and very welcome surprise\\xc2\\x97through its bumbling, unsure-of-himself, low-key star, whose ever-cool state is enticing, especially given his line of work.<br /><br />The forever-great William H. Macy again captures our hearts as Alex, a unhappy, torn, middle-aged husband and father who finds solace in the most dubious of persons: a young, attractive, equally-messed-up 23-year-old named Sarah (Neve Campbell), whom he meets in the waiting-room at a psychologist's office, where he awaits the therapy of Dr. Josh Parks (John Ritter) to discuss his growing eagerness to quit the family business that his father (Donald Sutherland) built. Alex, whose lust to lead a new life is obstructed by the fear of disappointing his dictating father, strikes an unwise fancy for Sarah, which ultimately leads him to understand the essence and irrefutable responsibility of being a husband to his wife and, more importantly to him, a good father to his six-year-old son, Sammy (played enthusiastically by the endearing David Dorfman).<br /><br />Henry Brommell's brilliant 'Panic' is something of a rarity in Hollywood seldom seen (with the exception of 2002's 'Road to Perdition') since its conception in 2000\\xc2\\x97it weaves two conflicting genres (organized-crime, family drama) into a fascinating, warm hunk of movie-viewing that is evenly strong in either direction\\xc2\\x97and it's one that will maintain its exceptional, infrequent caliber and gleaming sincerity for ages to come.\"\n",
            "Round-trip:  in his first go as a hollywood director [UNK] [UNK] [UNK] an [UNK] [UNK] that is all of [UNK] [UNK] [UNK] [UNK] with [UNK] [UNK] and [UNK] such with an [UNK] [UNK] [UNK] of a [UNK] [UNK] business the film is directed [UNK] and [UNK] of a [UNK] put together cast as well as a [UNK] [UNK] screenplay also by [UNK] that brings life to an otherwise [UNK] genre as a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] and very [UNK] [UNK] its [UNK] [UNK] [UNK] star whose [UNK] [UNK] is [UNK] especially given his line of [UNK] br the [UNK] [UNK] [UNK] [UNK] again [UNK] our [UNK] as [UNK] a [UNK] [UNK] [UNK] husband and father who finds [UNK] in the most [UNK] of [UNK] a young [UNK] [UNK] [UNK] named [UNK] [UNK] [UNK] whom he meets in the [UNK] at a [UNK] [UNK] where he [UNK] the [UNK] of dr [UNK] [UNK] john [UNK] to [UNK] his [UNK] [UNK] to [UNK] the family business that his father [UNK] [UNK] [UNK] [UNK] whose [UNK] to lead a new life is [UNK] by the [UNK] of [UNK] his [UNK] father [UNK] an [UNK] [UNK] for [UNK] which [UNK] leads him to understand the [UNK] and [UNK] [UNK] of being a husband to his wife and more [UNK] to him a good father to his [UNK] son [UNK] played [UNK] by the [UNK] david [UNK] br [UNK] [UNK] brilliant [UNK] is something of a [UNK] in hollywood [UNK] seen with the [UNK] of [UNK] [UNK] to [UNK] since its [UNK] in [UNK] [UNK] two [UNK] [UNK] [UNK] family drama into a [UNK] [UNK] [UNK] of [UNK] that is [UNK] strong in either [UNK] its one that will [UNK] its [UNK] [UNK] [UNK] and [UNK] [UNK] for [UNK] to come                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Model"
      ],
      "metadata": {
        "id": "7hK9V4MuHcFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "9TuUvJAuHdHQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ],
      "metadata": {
        "id": "-y8VYmRNHj0U",
        "outputId": "2cc5a341-e668-49e4-8e11-1f0a094b3774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "id": "hxeA4wj1HomE",
        "outputId": "7c4fa94c-e77e-4b9b-f3bf-ccc4a1b840f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "[-0.00116372]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "id": "q0xEQju3HpLd",
        "outputId": "6ed2b88f-1738-4d0b-e64d-e72ef82d272f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 543ms/step\n",
            "[-0.00116372]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1N-dvmTyHrwW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "fiP8aAzJHwXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "id": "OyFyldDWHxUb",
        "outputId": "1e70549b-63b1-4216-b8d5-1f4335be4866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 734s 2s/step - loss: 0.6577 - accuracy: 0.5518 - val_loss: 0.5607 - val_accuracy: 0.7427\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 660s 2s/step - loss: 0.4252 - accuracy: 0.8010 - val_loss: 0.3707 - val_accuracy: 0.8302\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 630s 2s/step - loss: 0.3495 - accuracy: 0.8456 - val_loss: 0.3417 - val_accuracy: 0.8495\n",
            "Epoch 4/10\n",
            " 82/391 [=====>........................] - ETA: 7:42 - loss: 0.3233 - accuracy: 0.8588"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "Ou-dOrcqHt_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ],
      "metadata": {
        "id": "44vmWujaI3wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))"
      ],
      "metadata": {
        "id": "hqhDjWdgJKFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "NKHjcu5pJlTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "claxGseeJnU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "id": "1b7qyCFNJqAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "UW36WOVHJsGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        ""
      ],
      "metadata": {
        "id": "byTWqZFYJvPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Work 2"
      ],
      "metadata": {
        "id": "p8qIUvF-J0_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "J_eThxq6KPR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        ""
      ],
      "metadata": {
        "id": "3tcR3hsvJ2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"
      ],
      "metadata": {
        "id": "i5aTkpcUKI6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "Lm0qp2Q3KR7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "id": "NiP8fHNpKOS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "id": "hAqk-QVyKcJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n",
        ""
      ],
      "metadata": {
        "id": "z2trg9Y1KckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Processing"
      ],
      "metadata": {
        "id": "U_261uSpMFyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts=['abcdefg','xyz']\n",
        "chars=tf.strings.unicode_split(example_texts,input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "id": "RxNRsDRBMH6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars=tf.keras.layers.StringLookup(vocabulary=list(vocab),mask_token=None)\n"
      ],
      "metadata": {
        "id": "U4cx--zwNZzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids=ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "id": "ZWy30rajNbWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "2c1N656NNlw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars=chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "id": "Rz_Crp3pNo6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()\n"
      ],
      "metadata": {
        "id": "Y126anEkNvVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "qhEMEMDZN83e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids=ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "all_ids\n"
      ],
      "metadata": {
        "id": "axSH6MWrN9vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)\n"
      ],
      "metadata": {
        "id": "sDG-0-WwN7yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "id": "LfyDYUQYOHD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100\n"
      ],
      "metadata": {
        "id": "h74J1I6FOJx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "id": "lwtjjyVhOOEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())\n",
        ""
      ],
      "metadata": {
        "id": "dM-alihEOQFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "EAuMG1dmOepW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))\n"
      ],
      "metadata": {
        "id": "Vm7uva1-OtX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)\n"
      ],
      "metadata": {
        "id": "JFkX1AB4OwQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print(\"Input :\",text_from_ids(input_example))\n",
        "    print(\"Target:\",text_from_ids(target_example))"
      ],
      "metadata": {
        "id": "iUfGi21DOyUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Batch Training"
      ],
      "metadata": {
        "id": "G7r5IgHTPYmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "5jHIuD_ePYbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a model"
      ],
      "metadata": {
        "id": "lB_9lbK5PjSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        ""
      ],
      "metadata": {
        "id": "vknOsL9kPcjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "YUv00eCHPebL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "nlKXGJ7pPo7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test The model"
      ],
      "metadata": {
        "id": "RxegNYAEPqmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "id": "PMttujXyPscr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "glf3qSn3Pxmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices=tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "QJWmukJ3Pzoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices\n"
      ],
      "metadata": {
        "id": "LEPabUaUP1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\",text_from_ids(input_example_batch[0]))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\",text_from_ids(sampled_indices))\n",
        ""
      ],
      "metadata": {
        "id": "mULgEDZ6P1_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "IuswffAiP6tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "rSGerU5yP6iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "tbdGBeqsQAeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()\n"
      ],
      "metadata": {
        "id": "NlfFGtHRQBBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)\n"
      ],
      "metadata": {
        "id": "Z1zD3ruqQELB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Check Point"
      ],
      "metadata": {
        "id": "MhdgX0G3QFvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "V0BAlehjQHeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=20\n"
      ],
      "metadata": {
        "id": "4myLHjHVQJcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "WXsly95wQL5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Text"
      ],
      "metadata": {
        "id": "irwB1cORQPcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n"
      ],
      "metadata": {
        "id": "GsmaAc3fQNLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model=OneStep(model,chars_from_ids,ids_from_chars)"
      ],
      "metadata": {
        "id": "kdDWp6pXQUJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "id": "Das2l3qsQXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab ASsignment"
      ],
      "metadata": {
        "id": "5UZ6FmqzSi9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "qe2wyeejSnG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "9_0i3_IQTVKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "F-sbmmitTYpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)\n"
      ],
      "metadata": {
        "id": "9IZqPLXnTaHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        ""
      ],
      "metadata": {
        "id": "2Tdpzp5mTjIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}